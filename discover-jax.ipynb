{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering JAX\n",
    "\n",
    "Google JAX is a machine learning framework for **transforming numerical functions**. The primary functions of JAX are:\n",
    "\n",
    "1. grad: automatic differentiation\n",
    "2. jit: compilation\n",
    "3. vmap: auto-vectorization\n",
    "4. pmap: SPMD programming\n",
    "\n",
    "### Sources and interesting links\n",
    "\n",
    "* wikipedia <https://en.wikipedia.org/wiki/Google_JAX>\n",
    "* <https://jax.readthedocs.io/en/latest/notebooks/quickstart.html>\n",
    "* <https://colinraffel.com/blog/you-don-t-know-jax.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX Numpy\n",
    "\n",
    "`jax.numpy` and `numpy` objects and operations are often interchangeable thanks to duck-typing, a property of python that allows to operate on objects if they contain appropriate attributes and methods, rather than being of a specific type of object.\n",
    "\n",
    "Working with JAX arrays is computationally more efficient when `jit` is intensively used. `numpy` works only on CPUs, while `jax.numpy` also works on GPUs and TPUs.\n",
    "\n",
    "JAX arrays are immutable, contrary to numpy arrays. This is a condition for using `jit`. In practice, changing one value in a JAX array means creating a new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  1  2  3  4  5  6  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "# NumPy:\n",
    "x = np.arange(10)\n",
    "x[0] = 10\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  1  2  3  4  5  6  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "# JAX:\n",
    "y = jnp.arange(10)\n",
    "y = y.at[0].set(10)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2026465e+04 2.7182817e+00 7.3890562e+00 2.0085537e+01 5.4598152e+01\n",
      " 1.4841316e+02 4.0342880e+02 1.0966332e+03 2.9809580e+03 8.1030840e+03]\n",
      "[2.20264658e+04 2.71828183e+00 7.38905610e+00 2.00855369e+01\n",
      " 5.45981500e+01 1.48413159e+02 4.03428793e+02 1.09663316e+03\n",
      " 2.98095799e+03 8.10308393e+03]\n"
     ]
    }
   ],
   "source": [
    "# numpy and JAX are interchangeable in many places:\n",
    "print(jnp.exp(x))    # JAX sine function aplied to numpy array\n",
    "print(np.exp(y))     # Numpy sine function applied to JAX array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(2, dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.at[2].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9 10  1  2  3  4  5  6  7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(12, dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=jnp.roll(y,2)\n",
    "print(z)\n",
    "y[2]+z[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient calculation\n",
    "\n",
    "An example of automatic differentiation.\n",
    "\n",
    "By default, the gradient is taken with respect to the first argument; this can be controlled via the argnums argument to `jax.grad`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19661194\n",
      "[0.25       0.19661194 0.10499358]\n"
     ]
    }
   ],
   "source": [
    "# define the logistic function\n",
    "def logistic(x):  \n",
    "    return jnp.exp(x) / (jnp.exp(x) + 1)\n",
    "\n",
    "def sum_logistic(x):\n",
    "    return jnp.sum(logistic(x))\n",
    "\n",
    "# obtain the gradient functions\n",
    "grad_logistic = grad(logistic)\n",
    "grad_sum_logistic = grad(sum_logistic)\n",
    "\n",
    "# evaluate the gradient of the logistic function at x = 1 \n",
    "print( grad_logistic(1.0) )\n",
    "\n",
    "# evaluate the gradient of the sum_logistic function at [0,1,2]\n",
    "# Note that the array is created with jnp\n",
    "x_small = jnp.arange(3.)\n",
    "print( grad_sum_logistic(x_small) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.25      , 0.19661194, 0.10499358, 0.04517668], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(4.)\n",
    "grad_sum_logistic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT: Just-In-Time compilation\n",
    "\n",
    "JIT is an important ingredient for JAX numerical efficiency, but it takes a little bit of time and effort (and pain) to understand how to use it efficiently and without errors.\n",
    "\n",
    "When a numpy function is called, it is first compiled, then applied to the arguments. This is done each time the function is called. JIT offers the possibility to compile a function once for all when it is first called. At future calls, it is not re-compiled. This saves time but imposes a certain number of constraints on the arguments (In particular, arrays must be immutable) and the type of operations performed in the function.\n",
    "\n",
    "Check <https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:  1.0\n",
      "JAX:  1.0\n",
      "numpy:  1.0\n",
      "JAX:  1.0\n",
      "numpy:  1.0\n",
      "JAX:  1.0\n",
      "numpy:  1.0\n",
      "JAX:  1.0\n"
     ]
    }
   ],
   "source": [
    "# define the cube function\n",
    "def cube(x):\n",
    "    return x * x * x\n",
    "\n",
    "# generate data\n",
    "x = jnp.ones((20000, 10000))\n",
    "\n",
    "# create the jit version of the cube function\n",
    "jit_cube = jit(cube)\n",
    "\n",
    "# apply the cube and jit_cube functions to the same data for spreed comoparion\n",
    "for i in range(2):\n",
    "    print('numpy: ',cube(x)[0,0])\n",
    "    print('JAX: ',jit_cube(x)[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VMAP: Vectorization\n",
    "\n",
    "To be developed. Vectorization basically consists in organizing operations for easy parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
