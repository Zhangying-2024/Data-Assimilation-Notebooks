{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The methane global cycle and estimation of emissions\n",
    "\n",
    "This notebook explores the simplest data assimilation methods with one of the simplest model.   A more advanced perspetive is modestly introduced at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class\n",
    "\n",
    "The global $CH_4$ cycle is studied using a 2-box model. The boxes represent the Northern and Southern hemispheres. $CH_4$ masses are driven by surface emissions, chemical losses and interhemispheric transport.\n",
    "\n",
    "Emissions undergo seasonal variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"2-box model to study global CH4 cycle with simple data assimilation.\n",
    "    TO DO NEXT:\n",
    "    - MAKE IT POSSIBLE TO HANDLE OBSERVATIONS OF SELF.CONC[1]\n",
    "    - READ OBS IN EXTERNAL FILE\n",
    "    - SIMPLIFY MANAGEMENT OF TIME: self.time vs day...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nmembers=1):\n",
    "        self.nmembers = nmembers\n",
    "        self.conc = np.ones((2,self.nmembers))*20000.\n",
    "        self.dt = 1.                   # in days\n",
    "        self.time = 0.\n",
    "        self.kflux = 1./(1.5*365)      # interhemisphere transport time\n",
    "        self.loss = 1./(10.*365)       # life time 10 years\n",
    "        self.conc_series = []\n",
    "        self.time_series = []\n",
    "        self.variability=[]\n",
    "        \n",
    "        # Baseline emission and transport rates\n",
    "        self.base_Emissions  = np.outer( np.array([10.,1.]), np.ones(self.nmembers) )  # emissions \n",
    "        self.both_Hemisphere = np.outer( np.array([1.,-1.]), np.ones(self.nmembers) )  # transport directions\n",
    "        self.transport_param = np.outer( np.array([0.2,0.1]), np.ones(self.nmembers) ) # transport rates\n",
    "        \n",
    "        # add seasonal variability of emissions (opposite phases in noth hemispheres)\n",
    "        self.factor_variability=0.5     \n",
    "        self.variability= np.sin(2*np.pi*np.arange(0,365)/365.)*self.factor_variability*np.array([[1.],[-1.]])\n",
    "        self.variability = self.variability[:,:,np.newaxis]        # This is for ensembles\n",
    "\n",
    "        # For nudging. Those parameters are prescribed at call of run function.\n",
    "        self.k_nudging = 0.\n",
    "        self.day_interval = 0\n",
    "        \n",
    "        # To compute MSE\n",
    "        self.mse = np.zeros(self.nmembers)\n",
    "        \n",
    "        # For ensembles. Perturb emission amplitudes and inter-hemispheric transport rates.\n",
    "        if self.nmembers > 1: \n",
    "            zero2 = np.zeros(2)\n",
    "            iden2 = np.eye(2)\n",
    "            self.base_Emissions += 1.5 * np.transpose(np.random.multivariate_normal(zero2,iden2,self.nmembers))\n",
    "            self.transport_param += 0.02 * np.transpose(np.random.multivariate_normal(zero2,iden2,self.nmembers))\n",
    "            \n",
    "    def initialize(self, xc, day=0):\n",
    "        \"\"\"reinitialize model. xc here is a 2-entry array.\"\"\"\n",
    "        for ie in range(self.nmembers):\n",
    "            self.conc[:,ie] = xc\n",
    "        self.time = day\n",
    "        self.conc_series = []\n",
    "        self.time_series = []\n",
    "        \n",
    "    def rungekutta(self, func_in):\n",
    "        \"\"\"update concentration with a Runge-Kutta 4 step.\n",
    "        func_in is the RHS term of the equation. func_in only takes a conc array as argument.\"\"\"\n",
    "        k1 = func_in(self.conc) * self.dt\n",
    "        xtmp = self.conc + 0.5 * k1\n",
    "        k2 = func_in(xtmp) * self.dt\n",
    "        xtmp = self.conc + 0.5 * k2\n",
    "        k3 = func_in(xtmp) * self.dt\n",
    "        xtmp = self.conc + k2\n",
    "        k4 = func_in(xtmp) * self.dt\n",
    "        self.conc += (k1+2*k2+2*k3+k4)/6.\n",
    "        \n",
    "    def rhs(self, xc):\n",
    "        \"\"\"Compute the right-hand-side term of the 2-box differential equation.\"\"\"\n",
    "        rhs_out = np.empty_like(xc)\n",
    "        flux1 = -self.kflux*xc[0,] + self.kflux*xc[1,]\n",
    "        # Emissions are base emissions + seasonal variability (based on the day )\n",
    "        day = int(self.time)\n",
    "        Emissions = self.base_Emissions * (1 + self.variability[:,day%365,] )       \n",
    "        rhs_out = Emissions - self.loss*xc + flux1*self.both_Hemisphere*self.transport_param\n",
    "        return rhs_out\n",
    "    \n",
    "    def nudging_coefficient(self, day, obsday):\n",
    "        \"\"\"Compute the nudging coefficient K. K is a hat function taking values\n",
    "        0 at day = obsday - or + day_interval, and self.k_nudging at day = obsday.\n",
    "        ----------\n",
    "        Parameters:\n",
    "        ----------\n",
    "        day: simulation day (integer of self.time)\n",
    "        obs_day: day of observation\n",
    "        -------\n",
    "        Returns:\n",
    "        -------\n",
    "        nudging coefficient. \n",
    "        \"\"\"\n",
    "        a = obsday-day\n",
    "        a = 1. - np.sign(a)*a/float(self.day_interval)\n",
    "        a = np.maximum(a,0.)\n",
    "        return self.k_nudging*a\n",
    "\n",
    "    def nudging_term(self, xc):\n",
    "        \"\"\"Compute the nudging term using all eligible observations.\n",
    "        IMPORTANT: AS TO NOW, IT IS HARDCODED THAT INDEX 0 OF SELF.CONC IS OBSERVED. THIS MUST BE IMPROVED.\"\"\"\n",
    "        nudg_out = np.zeros_like(xc)\n",
    "        day = int(self.time)\n",
    "        check_obs, obs_days, obs_values = self.observation(day)      # get obs. days and values for the day\n",
    "        if check_obs == True:\n",
    "            nobs = len(obs_days)\n",
    "            for io in range(nobs):\n",
    "                obsday = obs_days[io]\n",
    "                obsval = obs_values[io]\n",
    "                nudg_out[0,] += self.nudging_coefficient(day, obsday)*(obsval-self.conc[0,])           \n",
    "        return nudg_out\n",
    "        \n",
    "    def rhs_with_nudging(self, xc):\n",
    "        \"\"\"return RHS term expanded with nudging term. This is meant to be argument of the rungekutta function.\"\"\"\n",
    "        return self.rhs(xc) + self.nudging_term(xc)\n",
    "    \n",
    "\n",
    "    def run(self, days, mode='free', method='nudging', k_nudging=0.2, day_interval=20):\n",
    "        \"\"\"Run the model time integration, with or without data assimilation.\n",
    "        ----------\n",
    "        Parameters:\n",
    "        ----------\n",
    "        days: number of days of integration\n",
    "        mode: 'free' (default) or 'assim'.\n",
    "        method: assimilation method. 'substitution' or 'nudging' (default)\n",
    "        k_nudging: nudging coefficient. Default: 0.2\n",
    "        day_interval: time lag around observation time, over which nudging is applied. Default: 20\n",
    "        -------\n",
    "        Returns:\n",
    "        -------\n",
    "        no explicit outputs. Changes class attributes conc, conc_series, time, time_series\n",
    "        \"\"\"\n",
    "        nsteps = int(days/self.dt)     \n",
    "        _conc_series = np.zeros((2, nsteps+1, self.nmembers))\n",
    "        _conc_series[:,0,:] = self.conc\n",
    "        _time_series = np.empty(nsteps+1)\n",
    "        _time_series[0] = self.time\n",
    "        \n",
    "        if mode == 'free':\n",
    "            nobs = 0\n",
    "            for it in range(nsteps):\n",
    "            #for ie in range(self.nmembers):\n",
    "                self.time += self.dt\n",
    "                self.rungekutta(self.rhs)\n",
    "                _conc_series[:,it+1,:] = self.conc\n",
    "                _time_series[it+1] = self.time\n",
    "                day = int(self.time)\n",
    "                check_obs, obs_days, obs_values = self.observation(day)\n",
    "                if check_obs == True:\n",
    "                    nobs += 1\n",
    "                    self.mse += ( self.conc[0,] - obs_values[0] )**2\n",
    "            if nobs != 0:\n",
    "                self.mse /= nobs\n",
    "                self.mse = np.sqrt(self.mse)\n",
    "            \n",
    "        if mode == 'assim' and method == 'substitution':\n",
    "            for it in range(nsteps):\n",
    "            #for ie in range(self.nmembers):\n",
    "                self.time += self.dt\n",
    "                self.rungekutta(self.rhs)\n",
    "                day = int(self.time)\n",
    "                check_obs, obs_days, obs_values = self.observation(day)\n",
    "                if check_obs == True:\n",
    "                    self.conc[0,] = obs_values[0]\n",
    "                _conc_series[:,it+1,:] = self.conc\n",
    "                _time_series[it+1] = self.time\n",
    "            \n",
    "        if mode == 'assim' and method == 'nudging':\n",
    "            self.k_nudging = k_nudging\n",
    "            self.day_interval = day_interval\n",
    "            for it in range(nsteps):\n",
    "                self.time += self.dt\n",
    "                self.rungekutta(self.rhs_with_nudging)\n",
    "                _conc_series[:,it+1,:] = self.conc\n",
    "                _time_series[it+1] = self.time\n",
    "\n",
    "        if len(self.time_series) == 0:            # check empty list\n",
    "            self.time_series = _time_series\n",
    "            self.conc_series = _conc_series\n",
    "        else:\n",
    "            self.time_series = np.hstack((self.time_series, _time_series))\n",
    "            self.conc_series = np.hstack((self.conc_series, _conc_series))\n",
    "    \n",
    "    def read_obs(self):\n",
    "        day_list = [200, 400, 600, 800]\n",
    "        obs_val = [21850, 21400, 21745, 21520]\n",
    "        return day_list, obs_val\n",
    "    \n",
    "    \n",
    "    def observation(self, day):\n",
    "        \"\"\"Check if an obs is available for this day and get value.\n",
    "        In future designs, the first two arrays should be read externally.\"\"\"\n",
    "        day_list, obs_val = self.read_obs()\n",
    "        check = False\n",
    "        obsday = []\n",
    "        obsval = []\n",
    "        for day_tmp in day_list:\n",
    "            if day in range(day_tmp-self.day_interval, day_tmp+self.day_interval+1):\n",
    "                check = True\n",
    "                obsday = obsday + [day_tmp]\n",
    "                io = day_list.index(day_tmp)\n",
    "                obsval = obsval + [obs_val[io]]   \n",
    "        return check, obsday, obsval\n",
    "                \n",
    "    def plot_series(self):\n",
    "        x, y = self.read_obs()\n",
    "\n",
    "        plt.figure(figsize=(12,4))\n",
    "        for ie in range(self.nmembers):\n",
    "            ax1 = plt.subplot(1,2,1)\n",
    "            ax1.plot(self.time_series,self.conc_series[0,:,ie],'black',linewidth=1.)\n",
    "            ax1.plot(x,y,'bo')\n",
    "            ax1.set_title('North')\n",
    "            ax1.set_xlabel('time (days)')\n",
    "            ax1.set_ylabel('Concentration')\n",
    "            ax2 = plt.subplot(1,2,2)\n",
    "            ax2.plot(self.time_series,self.conc_series[1,:,ie],'red',linewidth=1.)\n",
    "            ax2.set_title('South')\n",
    "            ax2.set_xlabel('time (days)')\n",
    "            ax2.set_ylabel('Concentration')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Model equations\n",
    "\n",
    "**QUESTION: From the code above, retrieve the chemical model equations.** Disregard the assimilation and ensemble aspects for the moment. But look carefully at the Emission term.\n",
    "\n",
    "**QUESTION: Do you know the integration scheme used here?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spin-up\n",
    "\n",
    "Spin-up consists in running the model from poor initial conditions to let it reach sort of a statistical equilibrium. Here, the model is started with $CH_4$ quantities of 0 in both hemisphere, what is obviously inaccurate, but after a few years, the model reaches its equilibrium.\n",
    "\n",
    "More precisely, the model is run over 5000 days. The final concentration is stored in an array called `conc_init` which will be used later to initiate other simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinup = Model()\n",
    "spinup.run(365*100)\n",
    "conc_init = spinup.conc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a Model instance and initialize concentrations with ```conc_init```. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto = Model()\n",
    "toto.initialize(conc_init, day=0.)\n",
    "toto.run(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the simulation result. The blue dots represent observation of $CH_4$ in the first box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto.plot_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assimilation of observations (part 1)\n",
    "\n",
    "At day 200 an observation of $CH_4$ in the Northern hemisphere tells us that $CH_4$ quantity is $21850\\pm 50$. How can you take this information into account in order to correct the model trajectory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Brute force: replacing model variable with observation\n",
    "\n",
    "Try to replace the observed model variable directly with the observation value.\n",
    "\n",
    "**QUESTION: Spot the code line that implements the substitution.**\n",
    "\n",
    "**QUESTION: What does the ```observation``` function return?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi = Model()\n",
    "titi.initialize(conc_init, day=0.)\n",
    "titi.run(1000, mode='assim', method='substitution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi.plot_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. More subtle: nudging\n",
    "\n",
    "Nudging consists in replacing the original model equation:\n",
    "$$ \\frac{dX}{dt} = f(X,t) $$\n",
    "by the following equation:\n",
    "$$ \\frac{dX}{dt} = f(X,t) + K (X_{obs}(t) - X(t) )$$\n",
    "where $X_{obs}(t)$ is the observation values of $X(t)$ and $K$ is a nudging coefficient. Note that:\n",
    "\n",
    "- In absence of observation, the nudging term does not appear and the the original equation is retrieved;\n",
    "- Nudging at the single time of observation (i.e., once in the simulation) has little impact. Usually, the nudging term is activated some time before the observation time, with $K$ increasing from 0 to its prescribed value, then nudging is progressively deactivated by decreasing $K$ to 0.\n",
    "\n",
    "**QUESTION: Detail the shape of the nudging coefficient. What is the ```day_interval``` variable used for?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi = Model()\n",
    "titi.initialize(conc_init, day=0.)\n",
    "titi.run(1000, mode='assim', method='nudging', k_nudging = 0.05, day_interval = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi.plot_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Assimilation of observations (part 2)\n",
    "\n",
    "To account for observation uncertainty and obtain an estimation of the simulation uncertainty, a common method is to use ensembles. The idea is that the ensemble spread reflects the simulation uncertainty. At observation time, one can combine the ensemble and the observation based on their relative uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Ensemble simulation\n",
    "\n",
    "We create a new instance of the `Model` class with several ensemble members. Members are initialized with the previously computed `conc_init` value. Then the model is run in ensemble mode over the first 200 days. Members are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens = Model(nmembers = 100)\n",
    "toto_ens.initialize(conc_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens.run(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens.plot_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION: What are the sources of uncertainty considered in the model, and how are they simulated?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Comparison of the ensemble and the observation\n",
    "\n",
    "We reinitialize the ensemble and run it until the first observation. Then we plot the histogram of the ensemble, with probability density function of observation (assumed Gaussian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens = Model(nmembers = 100)\n",
    "toto_ens.initialize(conc_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_obs, val_obs = toto_ens.read_obs()\n",
    "iobs = 0\n",
    "toto_ens.run(day_obs[iobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens.plot_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(xarr, xm, std):\n",
    "    \"\"\"return gaussian function of sorted array xarr, with mean xm and standard deviation std.\"\"\"\n",
    "    s = (xarr - xm)/std\n",
    "    s = 0.5*s*s\n",
    "    s = np.exp(-s)\n",
    "    dx = np.roll(xarr, -1) - xarr\n",
    "    dx[-1] = dx[-2]\n",
    "    s /= np.sum(s*dx)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = np.arange(20000., 24000., 10.)\n",
    "gau = gauss(xxx, val_obs[iobs], 50.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(toto_ens.conc[0,:], bins=20)\n",
    "gau *= np.max(n)/np.max(gau)\n",
    "plt.plot(xxx, gau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Combining the ensemble and the observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This requires some theoretical background to be introduced in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(conc, obsmean, obsstd):\n",
    "    w = ( conc[0,:] - obsmean ) / obsstd\n",
    "    w = np.exp(-0.5*w*w)\n",
    "    w /= np.sum(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = compute_weight(toto_ens.conc, val_obs[iobs], 50.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(toto_ens.conc[0,:], weights, 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmem = np.shape(toto_ens.conc)[1]\n",
    "index = [0]*nmem\n",
    "cdf = np.empty(nmem)\n",
    "for i in range(nmem):\n",
    "    cdf[i] = np.sum(weights[:i+1])\n",
    "urand = np.random.random()/nmem\n",
    "for i in range(nmem):\n",
    "    index[i] = np.searchsorted(cdf, urand)\n",
    "    urand += 1./nmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens.conc = toto_ens.conc[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(toto_ens.conc[0,:], bins=20)\n",
    "plt.plot(xxx, gau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens.run(day_obs[iobs+1]-day_obs[iobs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto_ens.plot_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
