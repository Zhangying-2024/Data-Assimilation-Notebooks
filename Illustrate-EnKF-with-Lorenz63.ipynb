{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Kalman filtering with the Lorenz 63 system\n",
    "## Illustration of the benefit of advanced data assimilation methods\n",
    "\n",
    "* Emmanuel Cosme, 2017\n",
    "* Illustrate Ensemble Kalman filter with Lorenz 63 model\n",
    "\n",
    "This notebook illustrates in a simple way that for a dynamical system very sparsely observed, using an advanced data assimilation method (here, an Ensemble Kalman filter, EnKF) rather than a crude one (here, direct substitution of the observed variable with the observation) is essential to estimate the system.\n",
    "\n",
    "The illustration uses the 3-variable, chaotic Lorenz 63 system (https://en.wikipedia.org/wiki/Lorenz_system). This dynamical model is often used to test data assimilation methods, because it displays a chaotic behavior, as the atmosphere and the ocean do, with very low dimensionality.\n",
    "\n",
    "It is not necessary to know the Ensemble Kalman filter nor to understand the code below to follow the notebook. The code is not optimized and not general to keep it short. In particular, the EnKF implementation misses basic characteristics that are realistic (errors in the observations) or essential with systems of higher dimensions (localisation, inflation, computations in subspaces, etc).\n",
    "\n",
    "The main steps covered below are:\n",
    "- Definition of the Lorenz model\n",
    "- Test the Lorenz model and define a \"reference\" trajectory\n",
    "- Test model's sensitivity to changes in initial condition and a model parameter\n",
    "- Experiment assimilation of observation drawn from the reference trajectory into the model with changed initial condition and parameter: direct substitution, and Ensemble Kalman filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Lorenz model\n",
    "The Lorenz system is:\n",
    "$$ \\dot{x} = \\sigma (y-x) $$\n",
    "$$ \\dot{y} = x (\\rho -z ) -y $$\n",
    "$$ \\dot{z} = xy -\\beta z $$\n",
    "In the cell below, it is coded in a class with default parameters $\\sigma = 10$, $\\rho = 28$, $\\beta=8/3$, and initial condition $(1.5, -1.5, 21)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# Lorenz 63 model\n",
    "#-------------------------------------------------------\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__( self, nmembers = 1 ):\n",
    "        self.nmembers = nmembers\n",
    "        self.nx = 3                         # number of variables (Lorenz 63)\n",
    "        self.sigma = 10.\n",
    "        self.rho_ref = 28.\n",
    "        self.beta = 8./3.\n",
    "        self.dt = 0.01\n",
    "        self.x0 = np.array([1.5, -1.5, 20.])\n",
    "        self.xvar, self.rho = self.initial_condition()\n",
    "        self.xvar_series = []\n",
    "        self.time = 0.\n",
    "        self.time_series = []\n",
    "        \n",
    "    def initial_condition(self):\n",
    "        \"\"\"Define the initial condition\"\"\"\n",
    "        if self.nmembers == 1:\n",
    "            xout = self.x0.reshape((self.nx, 1))\n",
    "            rhoout = self.rho_ref\n",
    "        else:\n",
    "            p0 = 3.*np.eye(self.nx)\n",
    "            xout = np.random.multivariate_normal(self.x0, p0, self.nmembers).T\n",
    "            rhoout = np.random.normal(self.rho_ref+0.5, 0.64, self.nmembers)\n",
    "        return xout, rhoout\n",
    "\n",
    "    def rhs(self,x_in):\n",
    "        \"\"\"right hand side term of Lorenz 63\"\"\"\n",
    "        x_out=np.zeros_like(x_in)\n",
    "        x_out[0,]=self.sigma*(x_in[1,]-x_in[0,])\n",
    "        x_out[1,]=self.rho*x_in[0,]-x_in[1,]-x_in[0,]*x_in[2,]\n",
    "        x_out[2,]=x_in[0,]*x_in[1,]-self.beta*x_in[2,]\n",
    "        return x_out\n",
    "\n",
    "    def forward(self, nstep_in):\n",
    "        self.xvar_series = np.zeros((self.nx, nstep_in, self.nmembers))\n",
    "        self.time_series = np.zeros(nstep_in)\n",
    "        for it in range(nstep_in):\n",
    "            self.xvar_series[:,it,:] = self.xvar\n",
    "            self.time_series[it] = self.time\n",
    "            k1=self.rhs(self.xvar)*self.dt\n",
    "            xtmp=self.xvar+0.5*k1\n",
    "            k2=self.rhs(xtmp)*self.dt\n",
    "            xtmp=self.xvar+0.5*k2\n",
    "            k3=self.rhs(xtmp)*self.dt\n",
    "            xtmp=self.xvar+k2\n",
    "            k4=self.rhs(xtmp)*self.dt\n",
    "            self.xvar+=(k1+2*k2+2*k3+k4)/6.\n",
    "            self.time += self.dt\n",
    "  \n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(12,8))\n",
    "        for ix in range(self.nx):\n",
    "            pnum = 311+ix\n",
    "            plt.subplot(pnum)\n",
    "            for ie in range(self.nmembers):\n",
    "                plt.plot(self.time_series[:],self.xvar_series[ix,:,ie],'black',linewidth=1.)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation of the Lorenz system\n",
    "Below is a trajectory of the Lorenz system is represented in the phase space (3D, and X-Z plan below). The \"butterfly\" clearly shows two attractors. The system state can switch from one lob to the other when It is extremely difficult to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_test = Model()\n",
    "lorenz_test.forward(5000)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot(lorenz_test.xvar_series[0,:,0], lorenz_test.xvar_series[1,:,0], lorenz_test.xvar_series[2,:,0])\n",
    "ax.set_xlabel(\"X Axis\")\n",
    "ax.set_ylabel(\"Y Axis\")\n",
    "ax.set_zlabel(\"Z Axis\")\n",
    "ax.set_title(\"Lorenz Attractor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lorenz_test.xvar_series[0,:,0], lorenz_test.xvar_series[2,:,0], '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General set-up: length of integration\n",
    "Number of time steps for all experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference simulation\n",
    "Run and plot a reference simulation. This simulation will serve as \"truth\" from which observations will extracted and assimilated. The graphs display the time evolution of $x$, $y$, $z$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_ref = Model()\n",
    "lorenz_ref.forward(ntime)\n",
    "lorenz_ref.plot()\n",
    "true_state = lorenz_ref.xvar_series\n",
    "true_time = lorenz_ref.time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz model with inaccurate initial condition\n",
    "We define a \"wrong\" initial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_state = np.array([3., -3., 21.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we examine the consequences of initializing the model with this wrong state rather than the \"true\" one. On the graph, the reference simulation is in black, the one with the wrong initial condition is in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = Model()\n",
    "lo.x0 = np.copy(wrong_state)\n",
    "lo.xvar, lo.rho = lo.initial_condition()\n",
    "#lo.forward(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo.xvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_test1 = Model()\n",
    "lorenz_test1.x0 = np.copy(wrong_state)\n",
    "lorenz_test1.xvar, lorenz_test1.rho = lorenz_test1.initial_condition()\n",
    "lorenz_test1.forward(ntime)\n",
    "plt.figure(figsize=(12,8))\n",
    "for ix in range(3):\n",
    "    pnum = 311+ix\n",
    "    plt.subplot(pnum)\n",
    "    plt.plot(true_time,true_state[ix,:,0],'black',linewidth=1.,label='Reference')\n",
    "    plt.plot(lorenz_test1.time_series,lorenz_test1.xvar_series[ix,:,0],'red',linewidth=1.,label='Other')\n",
    "    plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz model with inaccurate parameters\n",
    "We now look at the consequences of a poor prescription of the $\\rho$ parameter: 29 instead of 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_test2 = Model()\n",
    "lorenz_test2.rho = 29.\n",
    "lorenz_test2.forward(ntime)\n",
    "plt.figure(figsize=(12,8))\n",
    "for ix in range(3):\n",
    "    pnum = 311+ix\n",
    "    plt.subplot(pnum)\n",
    "    plt.plot(true_time,true_state[ix,:,0],'black',linewidth=1.,label='Reference')\n",
    "    plt.plot(lorenz_test2.time_series,lorenz_test2.xvar_series[ix,:,0],'red',linewidth=1.,label='Other')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz model with inaccurate initial conditions and inaccurate parameters\n",
    "Finally, we put together a wrong initial state and an erroneous $\\rho$ parameter. This reflects what actually happens when one uses a numerical model of a geophysical system: the numerical model is never perfect, and the initial condition is never perfectly known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_test3 = Model()\n",
    "lorenz_test3.x0 = np.copy(wrong_state)\n",
    "lorenz_test3.xvar, lorenz_test3.rho = lorenz_test3.initial_condition()\n",
    "#lorenz_test3.rho = 29.\n",
    "lorenz_test3.forward(ntime)\n",
    "plt.figure(figsize=(12,8))\n",
    "for ix in range(3):\n",
    "    pnum = 311+ix\n",
    "    plt.subplot(pnum)\n",
    "    plt.plot(true_time,true_state[ix,:,0],'black',linewidth=1.,label='Reference')\n",
    "    plt.plot(lorenz_test3.time_series,lorenz_test3.xvar_series[ix,:,0],'red',linewidth=1.,label='Other')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data assimilation\n",
    "We now turn to data assimilation. We assume our model is inaccurate, and the initial condition is not perfectly known. To mimic this, we assimilate observations extracted from the reference simulation ($\\rho=28$, initial condition = (1.5, -1.5, 21) ) into an unperfect model ($\\rho=29$) initialized with unperfect conditions (3, -3, 21).\n",
    "\n",
    "To make the experiment even closer to reality, we assume we have observations of the first variable $x$ only, and at a very limited number of time steps. This is stated in the cell below, with other operations necessary for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nvarobs = 0\n",
    "#nvarobs = [0, 1]\n",
    "nvarobs = [0, 2]\n",
    "nobs = len(nvarobs)\n",
    "assim_steps = range(25,150,25)\n",
    "nassim = len(assim_steps)\n",
    "lencycle = np.hstack((assim_steps[0], np.ediff1d(assim_steps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First data assimilation experiment: direct substitution\n",
    "Here, the model is run and each time an observation is available, it replaces the corresponding model value. This results in the \"steps\" clearly visible for $x$ on the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_assim1 = Model()\n",
    "lorenz_assim1.x0 = np.copy(wrong_state)\n",
    "lorenz_assim1.xvar, lorenz_assim1.rho = lorenz_assim1.initial_condition()\n",
    "#lorenz_assim1.rho = 29.\n",
    "\n",
    "time1 = np.empty(ntime)\n",
    "xvar1 = np.empty((3, ntime, 1))\n",
    "\n",
    "for ic in range(nassim): \n",
    "    \n",
    "    ## Forecast\n",
    "    if ic == 0:\n",
    "        nstep = assim_steps[0]\n",
    "    else:\n",
    "        nstep = assim_steps[ic] - assim_steps[ic-1]\n",
    "        \n",
    "    lorenz_assim1.forward(nstep)\n",
    "    \n",
    "    if ic == 0:\n",
    "        time1 = lorenz_assim1.time_series\n",
    "        xvar1 = lorenz_assim1.xvar_series\n",
    "    else:\n",
    "        time1 = np.hstack( ( time1, lorenz_assim1.time_series ) )\n",
    "        xvar1 = np.concatenate( ( xvar1, lorenz_assim1.xvar_series ), axis = 1 )\n",
    "    \n",
    "    ## Analysis\n",
    "    index = np.argwhere( true_time == lorenz_assim1.time )\n",
    "    lorenz_assim1.xvar[nvarobs, 0] = true_state[nvarobs, index, 0]\n",
    "       \n",
    "## Last cycle\n",
    "lorenz_assim1.forward( ntime - assim_steps[-1] )\n",
    "time1 = np.hstack(( time1, lorenz_assim1.time_series ))\n",
    "xvar1 = np.concatenate( ( xvar1, lorenz_assim1.xvar_series ), axis = 1 )\n",
    "  \n",
    "## Plots\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for ix in range(3):\n",
    "    pnum = 311+ix\n",
    "    plt.subplot(pnum)\n",
    "    plt.plot(true_time,true_state[ix,:,0],'black',linewidth=1.,label='Reference')\n",
    "    plt.plot(time1,xvar1[ix,:,0],'red',linewidth=1.,label='Substit.')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second data assimilation experiment: Ensemble Kalman filter\n",
    "We perform the same experiment as above, same model, same observations, but with an Ensemble Kalman filter (EnKF). The EnKF is a Monte Carlo method, therefore requires the definition of an ensemble (sample) size. An estimation of the observation error variance is also needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmem = 30\n",
    "Robs = 1.e-4*np.eye(nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big difference between the direct substitution experimented earlier and the EnKF tested below is: at each analysis step (i.e., each time an observation of $x$ is available and processed to correct the model), direct substitution corrects $x$ only. The EnKF corrects all variables, even if the observation is partial. This results in a much more accurate estimation of the model trajectory, in particular after the last available observation (at time 1.25 on the x axis). Long after the last observation though, the EnKF trajectory tends to diverge again, for 2 reasons: (i) the estimation at time 1.25 is not perfect and the model is chaotic, and (ii) the model is unperfect.\n",
    "\n",
    "Note that the EnKF being a Monte Carlo method; it is the ensemble mean that is plotted in red below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lorenz_assim2 = Model(nmembers=nmem)\n",
    "lorenz_assim2.x0 = np.copy(wrong_state)\n",
    "lorenz_assim2.xvar, lorenz_assim2.rho = lorenz_assim2.initial_condition()\n",
    "lorenz_assim2.rho = 29.\n",
    "\n",
    "time2 = np.empty(ntime)\n",
    "xvar2 = np.empty((3, ntime, nmem))\n",
    "\n",
    "for ic in range(nassim):\n",
    "    \n",
    "    ## Forecast\n",
    "    if ic == 0:\n",
    "        nstep = assim_steps[0]\n",
    "    else:\n",
    "        nstep = assim_steps[ic] - assim_steps[ic-1]\n",
    "        \n",
    "    lorenz_assim2.forward(nstep)\n",
    "    \n",
    "    if ic == 0:\n",
    "        time2 = lorenz_assim2.time_series\n",
    "        xvar2 = lorenz_assim2.xvar_series\n",
    "    else:\n",
    "        time2 = np.hstack(( time2, lorenz_assim2.time_series ))\n",
    "        xvar2 = np.concatenate( ( xvar2, lorenz_assim2.xvar_series ), axis = 1 )\n",
    "    \n",
    "    ## Analysis\n",
    "    obs_index = np.argwhere( true_time == lorenz_assim2.time )\n",
    "    innovation = np.empty((nobs, nmem))\n",
    "    for ie in range(nmem):\n",
    "        innovation[:,ie] = true_state[nvarobs, obs_index, 0] - lorenz_assim2.xvar[nvarobs, ie]\n",
    "    xvar2mean = np.mean( lorenz_assim2.xvar, axis=1 )\n",
    "    anomalies = np.empty_like(lorenz_assim2.xvar)\n",
    "    for ie in range(lorenz_assim2.nmembers):\n",
    "        anomalies[:,ie] = lorenz_assim2.xvar[:,ie] - xvar2mean\n",
    "    anomalies /= np.sqrt(lorenz_assim2.nmembers)\n",
    "    hanom = anomalies[nvarobs, :]\n",
    "    innovmat = Robs + np.inner(hanom,hanom)\n",
    "    innovmat = np.linalg.inv(innovmat)\n",
    "    Kgain = np.inner(anomalies, hanom)\n",
    "    Kgain = np.inner(Kgain, innovmat)\n",
    "    lorenz_assim2.xvar = lorenz_assim2.xvar + np.inner( Kgain, innovation.T )\n",
    "       \n",
    "## Last cycle\n",
    "lorenz_assim2.forward( ntime - assim_steps[-1] )\n",
    "time2 = np.hstack(( time2, lorenz_assim2.time_series ))\n",
    "xvar2 = np.concatenate( ( xvar2, lorenz_assim2.xvar_series ), axis = 1 )\n",
    "\n",
    "## Plots\n",
    "\n",
    "xvar2mean = np.mean(xvar2, axis=2)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for ix in range(3):\n",
    "    pnum = 311+ix\n",
    "    plt.subplot(pnum)\n",
    "    plt.plot(true_time,true_state[ix,:,0],'black',linewidth=1.,label='Reference')\n",
    "    plt.plot(time2, xvar2mean[ix,:],'red',linewidth=1.,label='EnKF')\n",
    "    plt.legend()\n",
    "    for ie in range(nmem):\n",
    "        plt.plot(time2, xvar2[ix,:, ie],'blue',linewidth=1.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the ensemble variances are plotted. The analyses reduce the variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvar2var = np.var(xvar2, axis=2)\n",
    "plt.figure(figsize=(12,8))\n",
    "for ix in range(3):\n",
    "    pnum = 311+ix\n",
    "    plt.subplot(pnum)\n",
    "    plt.plot(time2, xvar2var[ix,:],'red',linewidth=1.,label='EnKF')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
